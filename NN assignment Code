import zipfile
import os
import tensorflow as tf
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras import Input


zip_path = '/content/homer_bart.zip'


extract_path = '/content/homer_bart'


with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)


data_dir = extract_path


batch_size = 32
img_height = 64
img_width = 64


dataset = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    image_size=(img_height, img_width),
    label_mode="binary",
    batch_size=batch_size,
    shuffle=True,
    seed=42
)


total_batches = tf.data.experimental.cardinality(dataset).numpy()
train_batches = int(0.9 * total_batches)
test_batches = total_batches - train_batches

train_data = dataset.take(train_batches)
test_data = dataset.skip(train_batches)

train_data = train_data.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
test_data = test_data.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)

preprocess = tf.keras.Sequential([
    tf.keras.layers.Rescaling(1./255)
])


model = tf.keras.Sequential()
model.add(Input((img_height, img_width, 3)))
model.add(preprocess)
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1, activation='sigmoid'))


model.compile(optimizer='adam',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),
              metrics=['accuracy'])


model.fit(train_data, epochs=40, batch_size=batch_size, verbose=1,validation_data=test_data)


loss, accuracy = model.evaluate(test_data)
print(f'Test Accuracy: {accuracy:.4f}')
