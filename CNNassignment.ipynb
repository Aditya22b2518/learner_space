{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aditya22b2518/learner_space/blob/week3/CNNassignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN assignment**(Do read the note at the end)"
      ],
      "metadata": {
        "id": "4kESsOo4IUhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description: Here we are going to use CNN to classify images of elephants,tigers,cheetah's and crocodiles. Basically multiclass classificiation using CNN."
      ],
      "metadata": {
        "id": "deWESXcqELuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q.1** Import all required modules"
      ],
      "metadata": {
        "id": "-tI6CGxtJraE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n"
      ],
      "metadata": {
        "id": "ML_oQP0SJu-c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q.2** Load data using image_dataset_from_directory(https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory)"
      ],
      "metadata": {
        "id": "PyPMlrh4H_h1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "zip_file_path = '/content/drive/My Drive/data.zip'\n",
        "extract_to = '/content/drive/My Drive/data_directory'\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "\n",
        "os.listdir(extract_to)\n"
      ],
      "metadata": {
        "id": "mmJtCqmeWcH-",
        "outputId": "c1bf560b-5053-4f7e-e178-1e7dab867504",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_dir = extract_to\n",
        "data = image_dataset_from_directory(data_dir, image_size=(224, 224), batch_size=32)\n"
      ],
      "metadata": {
        "id": "BoV0mpQ-fMZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Since data object is not iterable,we will create a nummpy iterator for data.\n",
        "*   Then use batch to iterate through our data\n",
        "\n"
      ],
      "metadata": {
        "id": "0Lz_opzEIkxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_iterator = data.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "YdeyCp3vIZJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch=data_iterator.next()"
      ],
      "metadata": {
        "id": "M0BrVzJgI0Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the below code and batch code 2-3 times to visualise the labels given to different animals."
      ],
      "metadata": {
        "id": "BFYhZBK8I7OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(ncols=4, figsize=(20, 20))\n",
        "for idx, img in enumerate(batch[0][:4]):\n",
        "    ax[idx].imshow(img.astype(int))\n",
        "    ax[idx].title.set_text(batch[1][idx])"
      ],
      "metadata": {
        "id": "0U_gObC_WfD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q.3** Map the data such that all pixel values lie between 0 and 1 using the **lambda function**"
      ],
      "metadata": {
        "id": "dlFxTOYEJHh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.map(lambda x, y: (x / 255.0, y))"
      ],
      "metadata": {
        "id": "ZQLDb494JQMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q.4** Split the data into train set and test set(and validation set if needed) using **data.take**(https://www.geeksforgeeks.org/tensorflow-js-tf-data-dataset-class-take-method/) and **data.skip**(https://www.geeksforgeeks.org/tensorflow-js-tf-data-dataset-skip-method/)"
      ],
      "metadata": {
        "id": "ngGqgBHVKIm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "total_batches = len(data)\n",
        "train_size = int(0.8 * total_batches)\n",
        "test_size = total_batches - train_size\n",
        "\n",
        "train_data = data.take(train_size)\n",
        "test_data = data.skip(train_size).take(test_size)\n"
      ],
      "metadata": {
        "id": "rm8j2Jl6KXJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the model**"
      ],
      "metadata": {
        "id": "6znfO5DkJU0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q.5** Write code to create CNN model including fully connected layers with softmax as final layer."
      ],
      "metadata": {
        "id": "BFS_ikF4JyKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "H9OPh20BKDnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q.6** Compile your model"
      ],
      "metadata": {
        "id": "qdegbXaZKdPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fz2VU4OSKmwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q.7** Fit your model with train set and make sure to keep **less epochs**(10-15) as the dataset size is very large."
      ],
      "metadata": {
        "id": "zfZijguvKpxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data, validation_data=test_data, epochs=10)"
      ],
      "metadata": {
        "id": "gHBM-8LTC-qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q.8** Test your code with test set"
      ],
      "metadata": {
        "id": "3Cq6ZBwKLLC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ],
      "metadata": {
        "id": "4Ryizmz1LRMM",
        "outputId": "dc610950-1417-4c93-fe37-563f2b7ebb4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2e8eba318c04>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not change this code\n",
        "if accuracy>=0.85:\n",
        "  print(f\"Congratulations, CNN assignment complete!! Your accuracy is {accuracy}\")\n",
        "else:\n",
        "  print(f\"Try again, not enough accuracy! Your accuracy is {accuracy}\" )"
      ],
      "metadata": {
        "id": "_BkSZvLLLYF8",
        "outputId": "785698bd-fa92-4ddd-e9c5-b1386b9cdf59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Congratulations, CNN assignment complete!! Your accuracy is 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note: 1. Many of you will get very high train accuracy but low test accuracy. This is called overfitting, this can be solved by increasing the train set size. If your getting low accuracy for both train and test, modify your layers in the model.**\n",
        "\n",
        "**2.Do use T4GPU.Ideally your first epoch will take quite sometime and rest of the epochs will be faster but if all your epochs are taking a lot of time, try starting a new gpu session(open a new gmail account and open colab on that) because your free gpu might have exhausted itself.**\n",
        "\n",
        "**3.Other than that everything should be fine, happy learning!!**"
      ],
      "metadata": {
        "id": "y91gKo0wLox0"
      }
    }
  ]
}